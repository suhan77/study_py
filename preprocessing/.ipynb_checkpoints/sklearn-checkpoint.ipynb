{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sikit-Learn의 전처리 기능 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 스케일링 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일링은 자료 집합에 적용되는 전처리 과정으로 모든 자료에 선형 변환을 적용하여 전체 자료의 분포를 <span style=\"color:red\">평균 0, 분산 1</span>이 되도록 만드는 과정이다.스케일링은 자료의 오버플로우(overflow)나 언더플로우(underflow)를 방지하고 독립 변수의 공분산 행렬의 조건수(condition number)를 감소시켜 최적화 과정에서의 안정성 및 수렴 속도를 향상시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn에서는 스케일링을 위한 함수와 클래스를 각각 제공한다. 스케일링 함수는 다음과 같다.\n",
    "\n",
    "- scale(X): 기본 스케일. 평균과 표준편차 사용\n",
    "- robust_scale(X): 중앙값(median)과 IQR(interquartile range) 사용. 아웃라이어의 영향을 최소화\n",
    "- minmax_scale(X): 최대/최소값이 각각 1, 0이 되도록 스케일링\n",
    "- maxabs_scale(X): 최대절대값과 0이 각각 1, 0이 되도록 스케일링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale, robust_scale, minmax_scale, maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>scale(x)</th>\n",
       "      <th>robust_scale(x)</th>\n",
       "      <th>minmax_scale(x)</th>\n",
       "      <th>maxabs_scale(x)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.950995</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>-0.789809</td>\n",
       "      <td>-0.777778</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>-0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.628624</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>-0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.467438</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.306253</td>\n",
       "      <td>-0.111111</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.145067</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.177304</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.338490</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2.756273</td>\n",
       "      <td>4.111111</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x  scale(x)  robust_scale(x)  minmax_scale(x)  maxabs_scale(x)\n",
       "0  -3.0 -0.950995        -1.000000         0.000000            -0.15\n",
       "1  -2.0 -0.789809        -0.777778         0.043478            -0.10\n",
       "2  -1.0 -0.628624        -0.555556         0.086957            -0.05\n",
       "3   0.0 -0.467438        -0.333333         0.130435             0.00\n",
       "4   1.0 -0.306253        -0.111111         0.173913             0.05\n",
       "5   2.0 -0.145067         0.111111         0.217391             0.10\n",
       "6   3.0  0.016119         0.333333         0.260870             0.15\n",
       "7   4.0  0.177304         0.555556         0.304348             0.20\n",
       "8   5.0  0.338490         0.777778         0.347826             0.25\n",
       "9  20.0  2.756273         4.111111         1.000000             1.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = (np.arange(9, dtype=np.float) - 3).reshape(-1, 1)\n",
    "x = np.vstack([x, [20]])  # outlier\n",
    "df = pd.DataFrame(np.hstack([x, scale(x), robust_scale(x), minmax_scale(x), maxabs_scale(x)]), \n",
    "                  columns=[\"x\", \"scale(x)\", \"robust_scale(x)\", \"minmax_scale(x)\", \"maxabs_scale(x)\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iris 데이터 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old mean: [5.84333333 3.05733333 3.758      1.19933333]\n",
      "old std:  [0.82530129 0.43441097 1.75940407 0.75969263]\n",
      "new mean: [-1.69031455e-15 -1.84297022e-15 -1.69864123e-15 -1.40924309e-15]\n",
      "new std:  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "data1 = iris.data\n",
    "data2 = scale(iris.data) # scale 적용\n",
    "\n",
    "print(\"old mean:\", np.mean(data1, axis=0))\n",
    "print(\"old std: \", np.std(data1, axis=0))\n",
    "print(\"new mean:\", np.mean(data2, axis=0))\n",
    "print(\"new std: \", np.std(data2, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler 클래스\n",
    "\n",
    "만약 파이프라인을 이용하면 스케일링을 함수가 아닌 Scaler 클래스로 구현해야 한다. scale 함수에 대응하는 클래스는 StandardScaler 클래스이다.\n",
    "\n",
    "Scaler 클래스의 사용 방법은 다음과 같다.\n",
    "\n",
    "1. 클래스 객체 생성\n",
    "2. fit() 메서드와 트레이닝 데이터를 사용하여 변환 계수 추정\n",
    "3. transform() 메서드를 사용하여 실제로 자료를 변환\n",
    "또는 fit_transform() 메서드를 사용하여 계수 추정과 자료 변환을 동시에 실행할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9738430577598278, 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data1)\n",
    "data2 = scaler.transform(data1)\n",
    "\n",
    "data1.std(), data2.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 정규화 (Normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정규화(Normarlization)는 스케일링과 달리 개별 <span style=\"color:red\">데이터의 크기를 모두 같게</span> 만들기 위한 변환이다. 따라서 개별 데이터에 대해 서로 다른 변환 계수가 적용된다.\n",
    "\n",
    "정규화는 다차원 독립 변수 벡터가 있을 때 각 벡터 원소들의 상대적 크기만 중요한 경우에 사용된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original x:\n",
      " [[-20.  -2.]\n",
      " [-19.  -1.]\n",
      " [-18.   0.]\n",
      " [-17.   1.]\n",
      " [-16.   2.]]\n",
      "scale:\n",
      " [[-1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678]\n",
      " [ 0.          0.        ]\n",
      " [ 0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356]]\n",
      "norms (scale)\n",
      " [2. 1. 0. 1. 2.]\n",
      "normlize:\n",
      " [[-0.99503719 -0.09950372]\n",
      " [-0.99861783 -0.05255883]\n",
      " [-1.          0.        ]\n",
      " [-0.99827437  0.05872202]\n",
      " [-0.99227788  0.12403473]]\n",
      "norms (normalize)\n",
      " [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "x = np.vstack([np.arange(5, dtype=float) - 20, np.arange(5, dtype=float) - 2]).T\n",
    "y1 = scale(x)\n",
    "y2 = normalize(x)\n",
    "\n",
    "print(\"original x:\\n\", x)\n",
    "print(\"scale:\\n\", y1)\n",
    "print(\"norms (scale)\\n\", np.linalg.norm(y1, axis=1))\n",
    "print(\"normlize:\\n\", y2)\n",
    "print(\"norms (normalize)\\n\", np.linalg.norm(y2, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 인코딩(Encoding)¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Label Encoder\n",
    "\n",
    "Label Encoder는 독립 변수가 아닌 종속 변수(라벨)에 대해 사용한다. 문자열이나 정수로된 라벨 값을  0  ~  K−1 까지의 정수로 변환한다. 변환된 규칙은 classes_ 속성에서 확인할 수 있다. 예측 결과에 적용할 수 있도록 역변환을 위한 inverse_transform 메서드도 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C'], dtype='<U1')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = ['A', 'B', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'B']\n",
    "le.fit(y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 2, 2, 0, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 변환하기\n",
    "y2 = le.transform(y) \n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 역변환하기\n",
    "le.inverse_transform(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Label Binarizer\n",
    "\n",
    "Label Binarizer는 one-hot-encoder와 유사하지만 독립 변수가 아닌 종속 변수(라벨) 값을 인코딩하는데 사용한다. Label Encoder와 마찬가지로 인코딩된 값에서 도로 라벨값으로 변환하는 역변환이 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y = ['A', 'B', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'B']\n",
    "lb.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C'], dtype='<U1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2 = lb.transform(y)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'A', 'A', 'B', 'C', 'C', 'A', 'C', 'B'], dtype='<U1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.inverse_transform(y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) One-Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(categories='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) 3 x 1 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0], [1], [2]])\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) 4x3 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 4],\n",
       "       [1, 1, 0],\n",
       "       [0, 2, 1],\n",
       "       [1, 0, 2]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([[0, 0, 4], [1, 1, 0], [0, 2, 1], [1, 0, 2]]) \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories='auto', drop=None,\n",
       "              dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "              n_values=None, sparse=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Inputer \n",
    "\n",
    "출처 : https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputer는 누락된 정보를 채우는 변환이다. 다음과 같은 인수를 제공한다.\n",
    "\n",
    "- missing_values : 누락 정보\n",
    "- strategy : 채우는 방법. 디폴트는 \"mean\"\n",
    "\n",
    "\"mean\": 평균\n",
    "\n",
    "\"median\": 중앙값\n",
    "\n",
    "\"most_frequent\": 최빈값\n",
    "\n",
    "\"constant\" : then replace missing values with fill_value. Can be used with strings or numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleImputer(add_indicator=False, copy=True, fill_value=None,\n",
       "              missing_values=nan, strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit([[7, 2, 3], [4, np.nan, 6], [10, 5, 9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Binarizer\n",
    "\n",
    "기준값(threshold)값을 기준으로 결과를 0, 1로 구분한다. 디폴트 기준값은 0 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "binarizer = Binarizer().fit(X) \n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = Binarizer(threshold=1.1)\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) PolynomialFeatures\n",
    "\n",
    "PolynomialFeatures 입력값  x 를 다항식으로 변환한다.\n",
    "\n",
    "x→[1,x,x2,x3,⋯]\n",
    " \n",
    "만약 열의 갯수가 두 개이고 2차 다항식으로 변환하는 경우에는 다음처럼 변환한다.\n",
    "\n",
    "[x1,x2]→[1,x1,x2,x21,x22,x1x2]\n",
    " \n",
    "다음과 같은 입력 인수를 가진다.\n",
    "\n",
    "- degree : 차수\n",
    "- interaction_only: interaction 항 생성 여부\n",
    "- include_bias : 상수항 생성 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.],\n",
       "       [ 1.,  2.,  3.,  6.],\n",
       "       [ 1.,  4.,  5., 20.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) FunctionTransformer\n",
    "\n",
    "FunctionTransformer 입력값  x 를 다항식이 아닌 사용자가 원하는 함수를 사용하여 변환한다.\n",
    "\n",
    "x→[f1(x),f2(x),f3(x),⋯]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "def kernel(X):\n",
    "    x0 = X[:, :1]\n",
    "    x1 = X[:, 1:2]\n",
    "    x2 = X[:, 2:3]\n",
    "    X_new = np.hstack([x0, 2 * x1, x2 ** 2, np.log(x1)])\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2],\n",
       "       [ 3,  4,  5],\n",
       "       [ 6,  7,  8],\n",
       "       [ 9, 10, 11]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(12).reshape(4, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   2.        ,   4.        ,   0.        ],\n",
       "       [  3.        ,   8.        ,  25.        ,   1.38629436],\n",
       "       [  6.        ,  14.        ,  64.        ,   1.94591015],\n",
       "       [  9.        ,  20.        , 121.        ,   2.30258509]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jsh\\Anaconda3\\envs\\tens2\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n",
      "C:\\Users\\jsh\\Anaconda3\\envs\\tens2\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:97: FutureWarning: The default validate=True will be replaced by validate=False in 0.22.\n",
      "  \"validate=False in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0.        ,   2.        ,   4.        ,   0.        ],\n",
       "       [  3.        ,   8.        ,  25.        ,   1.38629436],\n",
       "       [  6.        ,  14.        ,  64.        ,   1.94591015],\n",
       "       [  9.        ,  20.        , 121.        ,   2.30258509]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FunctionTransformer(kernel).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 파이프라인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지 설명한 전처리 객체는 Scikit-Learn의 파이프라인(pipeline) 기능을 이용하여 분류 모형과 합칠 수 있다. 예를 들어 표준 스케일러와 로지스틱 회귀 모형은 다음처럼 구성요소의 이름을 문자열로 추가하여 합친다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = Pipeline([\n",
    "            ('scaler', StandardScaler()), \n",
    "            ('classifier', LogisticRegression()),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "파이프라인으로 결합된 모형은 원래의 모형이 가지는 fit, predict 메서드를 가지며 각 메서드가 호출되면 그에 따른 적절한 메서드를 파이프라인의 각 객체에 대해서 호출한다. 예를 들어 파이프라인에 대해 fit 메서드를 호출하면 전처리 객체에는 fit_transform이 내부적으로 호출되고 분류 모형에서는 fit 메서드가 호출된다. 파이프라인에 대해 predict 메서드를 호출하면 전처리 객체에는 transform이 내부적으로 호출되고 분류 모형에서는 predict 메서드가 호출된다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
